{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Getting Started with Fine-Tuning Hibiki - 2B\n\nThis notebook is an example of how to LoRA finetune Hibiki 2B. Recommended GPU is **A100 GPU**.\n\nCheck out `moshi-finetune` Github repo to learn more: https://github.com/kyutai-labs/moshi-finetune/\n","metadata":{"id":"RyuOCYM92LJb"}},{"cell_type":"markdown","source":"## Setup\n\nClone the `hibiki-finetune` repo from my profile `imrnh`:\n","metadata":{"id":"yxr8mv-17GfB"}},{"cell_type":"code","source":"# Clone the repository\n!git clone https://github.com/imrnh/hibiki-finetune.git\n\n# Copy files to current directory (./)\n!cp -r hibiki-finetune/* ./\n!rm -rf hibiki-finetune\n\n# Install deps\n%pip install -e ./","metadata":{"id":"TIj3IlIeVDIb","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\nfrom huggingface_hub import snapshot_download\nimport os\nimport json\nimport yaml\n\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:06:57.755806Z","iopub.execute_input":"2025-08-13T10:06:57.756601Z","iopub.status.idle":"2025-08-13T10:06:58.218056Z","shell.execute_reply.started":"2025-08-13T10:06:57.756571Z","shell.execute_reply":"2025-08-13T10:06:58.217499Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Prepare dataset\n","metadata":{"id":"ams-19wF8zgY"}},{"cell_type":"code","source":"# Download the dataset\nPath(\"data/dailytalkm\").mkdir(parents=True, exist_ok=True)\nlocal_dir = snapshot_download(\"kyutai/DailyTalkContiguous\", repo_type=\"dataset\", local_dir=\"data/dailytalkm\")","metadata":{"id":"yDbw4DkJk9Gg","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths\ndata_stereo_folder = \"data/dailytalkm/data_stereo\"\noriginal_jsonl = \"data/dailytalkm/dailytalk.jsonl\"\noutput_jsonl = \"data/dailytalkm/dailytalk_m.jsonl\"\n\n# Get available indexes from data_stereo\navailable_indexes = set()\nfor f in os.listdir(data_stereo_folder):\n    if f.endswith(\".wav\"):\n        idx = os.path.splitext(f)[0]\n        if idx.isdigit():\n            available_indexes.add(idx)\n\n# Read original jsonl and filter\nwith open(original_jsonl, \"r\") as infile, open(output_jsonl, \"w\") as outfile:\n    for line in infile:\n        data = json.loads(line)\n        # Extract index from path, e.g., \"data_stereo/0.wav\" -> \"0\"\n        file_index = os.path.splitext(os.path.basename(data[\"path\"]))[0]\n        if file_index in available_indexes:\n            outfile.write(json.dumps(data) + \"\\n\")\n\nprint(f\"Filtered JSONL saved to {output_jsonl}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:10:55.364846Z","iopub.execute_input":"2025-08-13T10:10:55.365363Z","iopub.status.idle":"2025-08-13T10:10:55.382995Z","shell.execute_reply.started":"2025-08-13T10:10:55.365343Z","shell.execute_reply":"2025-08-13T10:10:55.382365Z"}},"outputs":[{"name":"stdout","text":"Filtered JSONL saved to data/dailytalkm/dailytalk_m.jsonl\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Write `trainer.yaml` file","metadata":{}},{"cell_type":"code","source":"config = \"\"\"\n# data\ndata:\n  train_data: 'data/dailytalkm/dailytalk_m.jsonl'\n  eval_data: ''\n  shuffle: true\n\n# model\nmoshi_paths:\n  hf_repo_id: \"kyutai/hibiki-2b-pytorch-bf16\"\n\nfull_finetuning: false # Activate lora.enable if partial finetuning\nlora:\n  enable: true\n  rank: 128\n  scaling: 2.\n  ft_embed: false\n\n# training hyperparameters\nfirst_codebook_weight_multiplier: 100.\ntext_padding_weight: .5\n\n\n# tokens per training steps = batch_size x num_GPUs x duration_sec\n# we recommend a sequence duration of 300 seconds\n# If you run into memory error, you can try reduce the sequence length\nduration_sec: 60\nbatch_size: 1\nmax_steps: 2\n\ngradient_checkpointing: true # Activate checkpointing of layers\n\n# optim\noptim:\n  lr: 2.e-6\n  weight_decay: 0.1\n  pct_start: 0.05\n\n# other\nseed: 0\nlog_freq: 1\neval_freq: 1\ndo_eval: False\nckpt_freq: 10\n\nsave_adapters: True\n\nrun_dir: \"run_dir\"\n\"\"\"","metadata":{"id":"5dxTlIQMaJGv","trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:11:47.674587Z","iopub.execute_input":"2025-08-13T10:11:47.675361Z","iopub.status.idle":"2025-08-13T10:11:47.679514Z","shell.execute_reply.started":"2025-08-13T10:11:47.675330Z","shell.execute_reply":"2025-08-13T10:11:47.678645Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# save the same file locally into the example.yaml file\nwith open(\"trainer.yaml\", \"w\") as file:\n    yaml.dump(yaml.safe_load(config), file)\n\n! rm -r run_dir # Remove run directory","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# start training\n!torchrun --nproc-per-node 1 -m train trainer.yaml","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4wFgmwIUTtg","outputId":"bc368932-edd4-4b0d-8d26-9489b8c6d183","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}